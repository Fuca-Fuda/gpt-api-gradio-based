{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353cff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  XXXXXXXX\n",
      "Running on public URL: XXXXXXXX\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c7ed1c0901642a2c54.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "import datetime\n",
    "import gradio as gr\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 获取程序开始运行的时间，然后用它来创建一个文件名\n",
    "start_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "filename = f\"{start_time}_history.txt\"\n",
    "\n",
    "# 创建一个名为\"History\"的子目录（如果它还不存在的话）\n",
    "os.makedirs(\"History\", exist_ok=True)\n",
    "\n",
    "# 完整的文件路径\n",
    "file_path = os.path.join(\"History\", filename)\n",
    "\n",
    "# 填入你的OPENAI_API_KEY\n",
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "########################################\n",
    "\n",
    "MAX_LENGTH = 16384   # 模型的最大token\n",
    "MAX_TOKENS = 2048# 生成响应的最大token\n",
    "# TOKEN_LENGTH = 2.1# 假设每个字符都会被编码为token_length个token\n",
    "\n",
    "MODEL_NAME = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "TEMPERATURE = 0.8  # 0-1，整体传统-整体创造\n",
    "TOP_P = 0.9  # 0-1，词汇选择少-词汇选择多\n",
    "FREQUENCY_PENALTY = 0  # 0-1，常见词多-常见词少\n",
    "PRESENCE_PENALTY = 0  # 0-1，曾用词多-曾用词少\n",
    "\n",
    "INTER_SWITCH = \"CONTINUOUS\" # 交互模式，0连续模式，1独立模式\n",
    "\n",
    "########################################\n",
    "\n",
    "messages = []\n",
    "history = []\n",
    "last_messages_input_index = None\n",
    "last_history_input_index = None\n",
    "last_user_input = \"\"\n",
    "his_count = 0\n",
    "\n",
    "def gpt_response(user_input):\n",
    "    try:\n",
    "        global messages, history, last_messages_input_index, last_history_input_index, last_user_input, his_count, TEMPERATURE, TOP_P, FREQUENCY_PENALTY, PRESENCE_PENALTY, MAX_LENGTH, MAX_TOKENS, MODEL_NAME, INTER_SWITCH\n",
    "\n",
    "        # 处理用户输入，删除末尾的空格和回车符\n",
    "        user_input = user_input.rstrip()\n",
    "        \n",
    "        # 找到massages中最后一次用户输入的消息索引\n",
    "        last_messages_input_index = None\n",
    "        for i in reversed(range(len(messages))):\n",
    "            if messages[i]['role'] == 'user':\n",
    "                last_messages_input_index = i\n",
    "                break\n",
    "        \n",
    "        # 找到history中最后一次用户输入的消息索引\n",
    "        last_history_input_index = None\n",
    "        for i in reversed(range(len(history))):\n",
    "            if history[i]['role'] == 'user':\n",
    "                last_history_input_index = i\n",
    "                break        \n",
    "\n",
    "        # 帮助信息\n",
    "        help_info_list = [\n",
    "        \"back >> ba/back\", \n",
    "        \"restart >> rs/restart\",\n",
    "        \"history >> ha/hr(all/recent 4)\",\n",
    "        \"system information >> info/information\", \n",
    "        \"interactive switch >> ic/ii(continuous/independent)\",\n",
    "        \"================================\", \n",
    "        \"gpt3/gpt4 model switch >> gpt3/gpt4\",\n",
    "        \"max tokens adjustment >> mt1/mt2/mt4/mt8(1024/2048/4096/8192)\",\n",
    "        \"mode switch >> lm/logic mode, gm/general mode, cm/creative mode\"\n",
    "        ]\n",
    "\n",
    "        # 使用join函数将列表中的各元素以换行符('\\n')连接\n",
    "        help_info = '\\n'.join(help_info_list)\n",
    "\n",
    "        # 检查输入是否要求显示帮助信息\n",
    "        if user_input.lower() in [\"help\", \"tips\", \"HELP\", \"TIPS\"]:\n",
    "            return help_info\n",
    "        \n",
    "        # 检查输入是否要求重置系统\n",
    "        elif user_input.lower() in [\"rs\", \"restart\", \"RS\", \"RESTART\"]:\n",
    "            messages = []\n",
    "            history = []\n",
    "            # last_user_input_index = None\n",
    "            return \"System has been reset.\"\n",
    "        \n",
    "        # 检查输入是否要求切换交互模式\n",
    "        elif user_input.lower() in [\"ic\", \"ii\", \"IC\", \"II\"]:\n",
    "            if user_input.lower() in [\"ic\",\"IC\"]:\n",
    "                INTER_SWITCH = \"CONTINUOUS\"\n",
    "                return f\"Switched to Continuous Interaction\"\n",
    "            else :\n",
    "                INTER_SWITCH = \"INDEPENDENT\"\n",
    "                return f\"Switched to Independent Interaction.\"\n",
    "        \n",
    "        # 检查输入是否要求切换模型\n",
    "        elif user_input.lower() in [\"gpt3\", \"gpt4\", \"GPT3\", \"GPT4\"]:\n",
    "            if user_input.lower() in [\"gpt3\",\"GPT3\"]:\n",
    "                MODEL_NAME = \"gpt-3.5-turbo-16k\"\n",
    "                MAX_LENGTH = 16384          \n",
    "                return f\"The model has now transitioned to gpt-3.5-turbo-16k.\"\n",
    "            else :\n",
    "                MODEL_NAME = \"gpt-4\"\n",
    "                MAX_LENGTH = 8192\n",
    "                return f\"The model has now transitioned to gpt-4.\"\n",
    "            \n",
    "        # 检查输入是否要调整最大tokens\n",
    "        elif user_input.lower() in [\"mt1\", \"mt2\", \"mt4\", \"mt8\", \"MT1\", \"MT2\", \"MT4\", \"MT8\"]:       \n",
    "            if user_input.lower() in [\"mt1\", \"MT1\"]:\n",
    "                MAX_TOKENS = 1024\n",
    "                return f\"The max_tokens has now transitioned to 1024.\"\n",
    "            elif user_input.lower() in [\"mt2\", \"MT2\"]:\n",
    "                MAX_TOKENS = 2048\n",
    "                return f\"The max_tokens has now transitioned to 2048.\"\n",
    "            elif user_input.lower() in [\"mt4\", \"MT4\"]:\n",
    "                MAX_TOKENS = 4096\n",
    "                return f\"The max_tokens has now transitioned to 4096.\"\n",
    "            else:\n",
    "                MAX_TOKENS = 8192\n",
    "                return f\"The max_tokens has now transitioned to 8192.\"\n",
    "\n",
    "        # 检查输入是否要求读取记录\n",
    "        elif user_input.lower() in [\"ha\", \"hr\", \"HA\", \"HR\"]:\n",
    "            # 从输出的txt文件中读取内容\n",
    "            if his_count != 0:  # 检查是否有聊天记录\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    output_content = f.read()\n",
    "\n",
    "                if user_input.lower() in [\"ha\", \"HA\"]:\n",
    "                    return output_content\n",
    "                elif user_input.lower() in [\"hr\", \"HR\"]:\n",
    "                    # 从文件的末尾开始，查找包含\"================================\"的行\n",
    "                    lines = output_content.split('\\n')\n",
    "                    target_lines = []\n",
    "                    count = 0\n",
    "                    target_index = -1  # 用于记录第五个出现\"===\"的行的索引\n",
    "\n",
    "                    for index, line in enumerate(reversed(lines)):\n",
    "                        if \"================================\" in line:\n",
    "                            count += 1\n",
    "                        if count == 5:\n",
    "                            target_index = len(lines) - 1 - index  # 找到第五个\"===\"行的索引\n",
    "                            break\n",
    "\n",
    "                    if target_index != -1:\n",
    "                        target_lines = lines[target_index:]  # 从第五个\"===\"开始到文件末尾的所有行\n",
    "                    else:\n",
    "                        target_lines = lines  # 如果不足五个\"===\"，则输出全部内容\n",
    "\n",
    "                    output_content = '\\n'.join(target_lines)\n",
    "\n",
    "                    return output_content\n",
    "            else:\n",
    "                return \"No conversation history available.\"\n",
    "            \n",
    "        # 检查输入是否要求删除上一次对话\n",
    "        elif user_input.lower() in [\"ba\", \"back\", \"BA\", \"BACK\"]:\n",
    "            if last_messages_input_index == None or last_messages_input_index == 0:\n",
    "                return \"No previous conversation to delete.\"\n",
    "            else:\n",
    "                # Remove the last user input and assistant response\n",
    "                messages = messages[:last_messages_input_index]\n",
    "                history = history[:last_history_input_index]\n",
    "                return \"Last conversation has been removed.\"\n",
    "\n",
    "        # 检查输入是否要求切换模式\n",
    "        elif user_input.lower() in [\"logic mode\", \"lm\"]:\n",
    "            TEMPERATURE = 0.5\n",
    "            TOP_P = 0.5\n",
    "            FREQUENCY_PENALTY = 0.0\n",
    "            PRESENCE_PENALTY = 0.0\n",
    "            return \"Switched to Logic Mode.\"\n",
    "\n",
    "        elif user_input.lower() in [\"general mode\", \"gm\"]:\n",
    "            TEMPERATURE = 0.8\n",
    "            TOP_P = 0.9\n",
    "            FREQUENCY_PENALTY = 0\n",
    "            PRESENCE_PENALTY = 0\n",
    "            return \"Switched to General Mode.\"\n",
    "\n",
    "        elif user_input.lower() in [\"creative mode\", \"cm\"]:\n",
    "            TEMPERATURE = 0.9\n",
    "            TOP_P = 0.9\n",
    "            FREQUENCY_PENALTY = 0.0\n",
    "            PRESENCE_PENALTY = 0.0\n",
    "            return \"Switched to Creative Mode.\"\n",
    "\n",
    "        # 检查输入是否要求显示参数\n",
    "        elif user_input.lower() in [\"info\", \"information\", \"INFO\", \"INFORMATION\"]:\n",
    "            cur_info = f\"MODEL_NAME = {MODEL_NAME}\\nMAX_LENGTH = {MAX_LENGTH}\\nMAX_TOKENS = {MAX_TOKENS}\\nTEMPERATURE = {TEMPERATURE}\\nTOP_P = {TOP_P}\\nFREQUENCY_PENALTY = {FREQUENCY_PENALTY}\\nPRESENCE_PENALTY = {PRESENCE_PENALTY}\\nINTER_SWITCH = {INTER_SWITCH}\"\n",
    "            return cur_info\n",
    "\n",
    "        # 如果没有匹配到以上的任何指令，处理正常的对话输入\n",
    "        else:\n",
    "            # 交互模式处理\n",
    "            if INTER_SWITCH == \"INDEPENDENT\":\n",
    "                messages = []\n",
    "                # history = []\n",
    "                # last_user_input_index = None\n",
    "                \n",
    "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "            history.append({\"role\": \"user\", \"content\": user_input})  # 保存用户输入到历史记录中\n",
    "            # last_messages_input_index = len(messages) - 1  # 更新上一次用户输入的索引\n",
    "            last_user_input = user_input  # 保存上一次用户输入\n",
    "\n",
    "        total_length = sum([len(tokenizer.tokenize(m['content'])) for m in messages])\n",
    "\n",
    "        # 如果总长度超过最大长度，就从第二条开始删除前面的部分，以完整的消息为单位删除\n",
    "        while total_length > MAX_LENGTH - MAX_TOKENS and len(messages) > 1:\n",
    "            removed_message = messages.pop(1)\n",
    "            total_length -= len(tokenizer.tokenize(removed_message['content']))\n",
    "\n",
    "        # history.append({\"role\": \"system\", \"content\": \"********************************\"})    \n",
    "        history.append({\"role\": \"system\", \"content\": \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"})\n",
    "\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=MODEL_NAME,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            top_p=TOP_P,\n",
    "            frequency_penalty=FREQUENCY_PENALTY,\n",
    "            presence_penalty=PRESENCE_PENALTY,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        chat_response = completion\n",
    "        answer = chat_response.choices[0].message.content\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        \n",
    "        # 重新找到massages中最后一次用户输入的消息索引\n",
    "        last_messages_input_index = None\n",
    "        for i in reversed(range(len(messages))):\n",
    "            if messages[i]['role'] == 'user':\n",
    "                last_messages_input_index = i\n",
    "                break\n",
    "        \n",
    "        # 重新找到history中最后一次用户输入的消息索引\n",
    "        last_history_input_index = None\n",
    "        for i in reversed(range(len(history))):\n",
    "            if history[i]['role'] == 'user':\n",
    "                last_history_input_index = i\n",
    "                break\n",
    "        \n",
    "        output_time = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "        history.append({\"role\": \"system\", \"content\": f\"(Input token: {int(total_length)}, Output token: {int(len(tokenizer.tokenize(answer)))})\"})\n",
    "        history.append({\"role\": \"system\", \"content\": f\"================[{output_time}]================\"})\n",
    "        \n",
    "        # 生成输出文本，在每条消息后面添加一个额外的换行符\n",
    "        output = \"\\n\\n\".join([f\">>Input:\\n{m['content']}\" if m['role'] == 'user' else f\">>Output:\\n{m['content']}\" if m['role'] == 'assistant' else m['content'] for m in history])\n",
    "\n",
    "        with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            save_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "            additional_content = f\"\\n\\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\n{save_time}\\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\n\"\n",
    "            f.write(output + additional_content + \"\\n\")\n",
    "            \n",
    "        his_count = his_count + 1\n",
    "\n",
    "        return user_input\n",
    "    \n",
    "    except Exception as e:\n",
    "        return str(e)  # 如果发生错误，将错误信息返回到Gradio界面上\n",
    "\n",
    "# 获取当前时间并格式化为字符串，例如\"2023-06-28 14:30\"\n",
    "title_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# Gradio Blocks创建：\n",
    "\n",
    "def handle_input(user_input):\n",
    "    global output_data\n",
    "    output_data = gpt_response(user_input)\n",
    "    return output_data\n",
    "\n",
    "def show_output():\n",
    "    global history\n",
    "    if history:\n",
    "        return \"\\n\\n\".join([f\">>Input:\\n{m['content']}\" if m['role'] == 'user' else f\">>Output:\\n{m['content']}\" if m['role'] == 'assistant' else m['content'] for m in history])\n",
    "    else:\n",
    "        return \"There's no previous conversation to recover. Please enter a new conversation.\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as gpt_ui:\n",
    "    gr.HTML(f\"<div style='font-size:24px;'><b>GPT-API ({title_time})</b></div>\")  # 设置标题\n",
    "    gr.HTML(\"<div style='text-align: left; font-size:16px;'>Enter help/tips for usage instructions.</div>\") # 文字说明\n",
    "    \n",
    "    input_box = gr.Textbox(label=\"Input\", lines=3)\n",
    "    with gr.Row():\n",
    "        clear_btn = gr.ClearButton(input_box)\n",
    "        input_btn = gr.Button(\"Input\")\n",
    "        input_btn.click(fn=handle_input, inputs=input_box, outputs=input_box, api_name=\"gpt_ui\")\n",
    "     \n",
    "    output_box = gr.Textbox(label=\"Output\")\n",
    "    show_btn = gr.Button(\"Refresh\")\n",
    "    show_btn.click(fn=show_output, outputs=output_box)\n",
    "\n",
    "gpt_ui.launch(share=True, enable_queue = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf2d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2453e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
